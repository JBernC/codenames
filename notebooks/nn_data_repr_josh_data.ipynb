{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs\n",
    "\n",
    "- predict vector instead of position in vocab? then do distance between vecs as loss?\n",
    "\n",
    "- MSE on number predicted rather than categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # hack to add module to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from codenames.greedy_matrix_helpers import restrict_vocab_to_english, restrict_vocab_with_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/miniconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CSV = \"../data/5k_conceptnet_game_data/10000_dataset.csv\"\n",
    "VOCAB_TXT = \"../data/5k_conceptnet_game_data/model_vocab.txt\"\n",
    "\n",
    "MODEL_NAME = \"conceptnet-numberbatch-17-06-300\"\n",
    "RESTRICTED_MODEL_NAME = f\"restricted_{MODEL_NAME}\"\n",
    "MODELS_DIR = \"../models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load wordvector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2VecKeyedVectors object from ../models/conceptnet-numberbatch-17-06-300\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '../models/conceptnet-numberbatch-17-06-300', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO:gensim.utils:loading vectors from ../models/conceptnet-numberbatch-17-06-300.vectors.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute vectors_norm to None\n",
      "INFO:gensim.utils:loaded ../models/conceptnet-numberbatch-17-06-300\n"
     ]
    }
   ],
   "source": [
    "with open(VOCAB_TXT) as f: \n",
    "    model_vocab = set(f.read().splitlines())\n",
    "\n",
    "model_path = os.path.join(MODELS_DIR, MODEL_NAME)\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    kv = KeyedVectors.load(model_path)\n",
    "else:\n",
    "    kv = api.load(MODEL_NAME)\n",
    "    kv.save(model_path)\n",
    "\n",
    "restrict_vocab_to_english(kv)\n",
    "restrict_vocab_with_set(kv, model_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>clue_number</th>\n",
       "      <th>intended_combo</th>\n",
       "      <th>words_guessed</th>\n",
       "      <th>cards</th>\n",
       "      <th>card_types</th>\n",
       "      <th>revealed_before_clue</th>\n",
       "      <th>team</th>\n",
       "      <th>red_team_guesses</th>\n",
       "      <th>blue_team_guesses</th>\n",
       "      <th>assassin_weight</th>\n",
       "      <th>enemy_weight</th>\n",
       "      <th>neutral_weight</th>\n",
       "      <th>ally_weight</th>\n",
       "      <th>risk_weight</th>\n",
       "      <th>clue_score_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fly</td>\n",
       "      <td>6</td>\n",
       "      <td>['lap', 'washington', 'strike', 'shadow', 'mos...</td>\n",
       "      <td>['strike', 'moscow', 'lap', 'bermuda', 'washin...</td>\n",
       "      <td>['telescope', 'mount', 'lion', 'kiwi', 'lap', ...</td>\n",
       "      <td>['neutral', 'red', 'neutral', 'blue', 'blue', ...</td>\n",
       "      <td>[True, True, True, True, True, False, False, T...</td>\n",
       "      <td>blue</td>\n",
       "      <td>['straw', 'carrot', 'america', 'buck', 'pan', ...</td>\n",
       "      <td>['telescope', 'strike', 'moscow', 'lap', 'berm...</td>\n",
       "      <td>-6.1032</td>\n",
       "      <td>-3.599553</td>\n",
       "      <td>-4.525893</td>\n",
       "      <td>10.12711</td>\n",
       "      <td>2.892535</td>\n",
       "      <td>0.071163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setting</td>\n",
       "      <td>2</td>\n",
       "      <td>['mount', 'plot']</td>\n",
       "      <td>['mount', 'plot']</td>\n",
       "      <td>['telescope', 'mount', 'lion', 'kiwi', 'lap', ...</td>\n",
       "      <td>['neutral', 'red', 'neutral', 'blue', 'blue', ...</td>\n",
       "      <td>[True, True, True, True, True, False, False, T...</td>\n",
       "      <td>red</td>\n",
       "      <td>['straw', 'carrot', 'america', 'buck', 'pan', ...</td>\n",
       "      <td>['telescope', 'strike', 'moscow', 'lap', 'berm...</td>\n",
       "      <td>-6.1032</td>\n",
       "      <td>-3.599553</td>\n",
       "      <td>-4.525893</td>\n",
       "      <td>10.12711</td>\n",
       "      <td>2.892535</td>\n",
       "      <td>0.071163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clue  clue_number                                     intended_combo  \\\n",
       "0      fly            6  ['lap', 'washington', 'strike', 'shadow', 'mos...   \n",
       "1  setting            2                                  ['mount', 'plot']   \n",
       "\n",
       "                                       words_guessed  \\\n",
       "0  ['strike', 'moscow', 'lap', 'bermuda', 'washin...   \n",
       "1                                  ['mount', 'plot']   \n",
       "\n",
       "                                               cards  \\\n",
       "0  ['telescope', 'mount', 'lion', 'kiwi', 'lap', ...   \n",
       "1  ['telescope', 'mount', 'lion', 'kiwi', 'lap', ...   \n",
       "\n",
       "                                          card_types  \\\n",
       "0  ['neutral', 'red', 'neutral', 'blue', 'blue', ...   \n",
       "1  ['neutral', 'red', 'neutral', 'blue', 'blue', ...   \n",
       "\n",
       "                                revealed_before_clue  team  \\\n",
       "0  [True, True, True, True, True, False, False, T...  blue   \n",
       "1  [True, True, True, True, True, False, False, T...   red   \n",
       "\n",
       "                                    red_team_guesses  \\\n",
       "0  ['straw', 'carrot', 'america', 'buck', 'pan', ...   \n",
       "1  ['straw', 'carrot', 'america', 'buck', 'pan', ...   \n",
       "\n",
       "                                   blue_team_guesses  assassin_weight  \\\n",
       "0  ['telescope', 'strike', 'moscow', 'lap', 'berm...          -6.1032   \n",
       "1  ['telescope', 'strike', 'moscow', 'lap', 'berm...          -6.1032   \n",
       "\n",
       "   enemy_weight  neutral_weight  ally_weight  risk_weight  \\\n",
       "0     -3.599553       -4.525893     10.12711     2.892535   \n",
       "1     -3.599553       -4.525893     10.12711     2.892535   \n",
       "\n",
       "   clue_score_threshold  \n",
       "0              0.071163  \n",
       "1              0.071163  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_CSV)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_strlist(strlist):\n",
    "    strlist = strlist.replace(\"'\", \"\\\"\")\n",
    "    return json.loads(strlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_types = [\"blue\", \"red\", \"neutral\", \"assassin\"]\n",
    "tile_type_dict = {v:k for k,v in enumerate(tile_types)}\n",
    "n_tile_types = len(tile_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b45846176ef4be997aa28a1b50814da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2cae61d864171a39e89eac1f8075b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"cards_parsed\"] = df[\"cards\"].progress_map(parse_strlist)\n",
    "df[\"card_types_parsed\"] = df[\"card_types\"].progress_map(parse_strlist).map(lambda card_types: [tile_type_dict[ct] for ct in card_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 25\n",
    "V = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca87770cba0456dbd89bd658fa87df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250025.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "card_types = np.vstack(df.card_types_parsed.values)\n",
    "\n",
    "z = [[kv.get_vector(word) for word in cards] for cards in df.cards_parsed]\n",
    "z = np.array(z)\n",
    "\n",
    "z = z.reshape(-1, V)\n",
    "\n",
    "X = np.zeros((z.shape[0], n_tile_types, V), dtype=np.float32)\n",
    "\n",
    "flat_card_types = card_types.flatten()\n",
    "\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    X[i, flat_card_types[i]] = z[i]\n",
    "    \n",
    "del z\n",
    "\n",
    "# back to desired shape\n",
    "X = X.reshape(n_samples, M, n_tile_types, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deal with y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2ind = {word:i for i, word in (enumerate(kv.vocab.keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_word =  df.clue.map(vocab2ind).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2809, 52),\n",
       " (3623, 42),\n",
       " (3677, 37),\n",
       " (305, 37),\n",
       " (1828, 36),\n",
       " (4205, 35),\n",
       " (3522, 35),\n",
       " (496, 34),\n",
       " (275, 33),\n",
       " (1106, 33),\n",
       " (4034, 33),\n",
       " (629, 31),\n",
       " (166, 31),\n",
       " (2837, 30),\n",
       " (2168, 30),\n",
       " (1160, 29),\n",
       " (1566, 29),\n",
       " (3624, 29),\n",
       " (3055, 28),\n",
       " (4251, 28)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO review lack of representation for each target\n",
    "from collections import Counter\n",
    "Counter(y_word).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_word = to_categorical(y_word, num_classes=y_word.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num = df.clue_number.values\n",
    "y_num = to_categorical(y_num, num_classes=y_num.max()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10001, 25, 4, 300), (10001, 4342), (10001, 8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y_word.shape, y_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do some data augmentation \n",
    "\n",
    "shuffle each board n times to create a dataset n times as big.\n",
    "\n",
    "WARNING - TAKES A LOT OF RAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dcb7c5cc214280ae4930d08363c8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aug_multiplier = 10\n",
    "X_aug = np.zeros((aug_multiplier*X.shape[0],) + X.shape[1:], dtype=np.float32)\n",
    "counter = 0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    for j in range(10):\n",
    "        X_aug[counter] = np.random.permutation(X[i])\n",
    "        counter += 1\n",
    "\n",
    "y_word_aug = np.tile(y_word, 10).reshape((X_aug.shape[0], y_word.shape[1]))\n",
    "y_num_aug = np.tile(y_num, 10).reshape((X_aug.shape[0], y_num.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100010, 25, 4, 300), (100010, 4342), (100010, 8))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aug.shape, y_word_aug.shape, y_num_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = X_aug.reshape(X_aug.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_flat.shape[1:]\n",
    "word_output_size = y_word.shape[1]\n",
    "num_output_size = y_num.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000,), 4342, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape, word_output_size, num_output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again pretty expensive on RAM as we've got a rather large X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_word_train, y_word_test, y_num_train, y_num_test = train_test_split(\n",
    "    X_flat, y_word_aug, y_num_aug, test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_flat, X_aug, y_word_aug, y_num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 30000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 1000)         30001000    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_word (Dense)              (None, 4342)         4346342     layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 5342)         0           layer1[0][0]                     \n",
      "                                                                 dense_word[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "out_word (Softmax)              (None, 4342)         0           dense_word[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "out_num (Dense)                 (None, 8)            42744       concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 34,390,086\n",
      "Trainable params: 34,390,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "633/633 [==============================] - 108s 170ms/step - loss: 8.6298 - out_word_loss: 7.4400 - out_num_loss: 1.1899 - out_word_accuracy: 0.0054 - out_num_accuracy: 0.6369 - val_loss: 8.1763 - val_out_word_loss: 7.1245 - val_out_num_loss: 1.0518 - val_out_word_accuracy: 0.0138 - val_out_num_accuracy: 0.6696\n",
      "Epoch 2/10\n",
      "633/633 [==============================] - 107s 169ms/step - loss: 5.5064 - out_word_loss: 4.5126 - out_num_loss: 0.9937 - out_word_accuracy: 0.2507 - out_num_accuracy: 0.6802 - val_loss: 6.5636 - val_out_word_loss: 4.7517 - val_out_num_loss: 1.8119 - val_out_word_accuracy: 0.1072 - val_out_num_accuracy: 0.6494\n",
      "Epoch 3/10\n",
      "633/633 [==============================] - 111s 176ms/step - loss: 0.5334 - out_word_loss: 0.1984 - out_num_loss: 0.3350 - out_word_accuracy: 0.9793 - out_num_accuracy: 0.9248 - val_loss: 7.8984 - val_out_word_loss: 4.5042 - val_out_num_loss: 3.3942 - val_out_word_accuracy: 0.1188 - val_out_num_accuracy: 0.6319\n",
      "Epoch 4/10\n",
      "633/633 [==============================] - 105s 166ms/step - loss: 0.3519 - out_word_loss: 0.0744 - out_num_loss: 0.2775 - out_word_accuracy: 0.9958 - out_num_accuracy: 0.9530 - val_loss: 10.3489 - val_out_word_loss: 4.5718 - val_out_num_loss: 5.7771 - val_out_word_accuracy: 0.1179 - val_out_num_accuracy: 0.6289\n",
      "Epoch 5/10\n",
      "116/633 [====>.........................] - ETA: 2:14 - loss: 0.2188 - out_word_loss: 0.0675 - out_num_loss: 0.1513 - out_word_accuracy: 0.9939 - out_num_accuracy: 0.9697"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3a5826b9564c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_word_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inp = layers.Input(shape=input_shape, name=\"input\")\n",
    "dense_1 = layers.Dense(1000, activation=\"relu\", name=\"layer1\")(inp)\n",
    "dense_word = layers.Dense(word_output_size, name=\"dense_word\", activation=None)(dense_1)\n",
    "\n",
    "concat = layers.concatenate((dense_1, dense_word), name=\"concat\")\n",
    "\n",
    "out_word = layers.Softmax(name=\"out_word\")(dense_word)\n",
    "\n",
    "out_num = layers.Dense(num_output_size, name=\"out_num\", activation=\"softmax\")(concat)\n",
    "\n",
    "model = keras.Model(inputs=(inp,), outputs=(out_word,out_num))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(lr=0.002), metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, (y_word_train, y_num_train), batch_size=128, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 4s 56ms/step - loss: 10.3369 - out_word_loss: 4.5930 - out_num_loss: 5.7440 - out_word_accuracy: 0.1127 - out_num_accuracy: 0.6082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.336933135986328,\n",
       " 4.592963695526123,\n",
       " 5.743966102600098,\n",
       " 0.11265414953231812,\n",
       " 0.6081546545028687]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, (y_word_test, y_num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num acc. suspiciously high, check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1502, 2: 6619, 3: 1302, 4: 394, 5: 142, 6: 41, 7: 1})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(np.argmax(y_num_test, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
